{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt/lNHbwkqJiFa8zhHSiJl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ironsoldier353/ML_project_01/blob/main/Predict_sale_price_optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries"
      ],
      "metadata": {
        "id": "PQ9DxkX5OTgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "wlioHcbPOPyo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "Di6p4H5sOXo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "bG8zGQsMOgiR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the data"
      ],
      "metadata": {
        "id": "_OL92LYZOt9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target from training data\n",
        "X = train_data.drop('SalePrice', axis=1)\n",
        "y = train_data['SalePrice']\n",
        "\n",
        "# Define your feature columns based on the dataset\n",
        "numeric_features = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
        "                    'YearRemodAdd', 'MasVnrArea', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
        "                    'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
        "                    'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'WoodDeckSF', 'OpenPorchSF',\n",
        "                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
        "                    'MoSold', 'YrSold', 'GarageCars', 'GarageArea']\n",
        "\n",
        "categorical_features = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour',\n",
        "                        'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1',\n",
        "                        'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl',\n",
        "                        'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
        "                        'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
        "                        'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n",
        "                        'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n",
        "                        'GarageQual', 'GarageCond', 'PavedDrive', 'Fence', 'MiscFeature',\n",
        "                        'SaleType', 'SaleCondition']\n",
        "\n",
        "# Ensure test_data has the same columns as X\n",
        "test_data = test_data[numeric_features + categorical_features]\n",
        "\n",
        "# Preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), numeric_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "        ]), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Split data\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "G6ivIcnfOrfK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "mkXoMRv8O8dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Gradient Boosting model pipeline\n",
        "gbm_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', GradientBoostingRegressor())\n",
        "])\n",
        "\n",
        "# Reduce hyperparameter search space\n",
        "param_distributions = {\n",
        "    'regressor__n_estimators': [100, 200],\n",
        "    'regressor__learning_rate': [0.01, 0.1],\n",
        "    'regressor__max_depth': [3, 5],\n",
        "    'regressor__min_samples_split': [2, 5],\n",
        "    'regressor__min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning with fewer iterations and folds\n",
        "random_search = RandomizedSearchCV(estimator=gbm_model, param_distributions=param_distributions,\n",
        "                                    n_iter=5, cv=3, scoring='r2', n_jobs=-1, verbose=2, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best parameters found for Gradient Boosting: \", random_search.best_params_)\n",
        "print(\"Best R² score found for Gradient Boosting: \", random_search.best_score_)\n",
        "\n",
        "# Evaluate on validation data\n",
        "y_pred_gbm = random_search.best_estimator_.predict(X_valid)\n",
        "rmse_gbm = np.sqrt(mean_squared_error(y_valid, y_pred_gbm))\n",
        "r2_gbm = r2_score(y_valid, y_pred_gbm)\n",
        "\n",
        "print(f'Gradient Boosting RMSE: {rmse_gbm:.2f}')\n",
        "print(f'Gradient Boosting R²: {r2_gbm:.4f}')\n",
        "\n",
        "# Transform the test data using the fitted preprocessor\n",
        "test_features_transformed = random_search.best_estimator_.named_steps['preprocessor'].transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV2neHTGPEyC",
        "outputId": "49b1dd51-573b-427e-ee09-fb910f47a3c0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Best parameters found for Gradient Boosting:  {'regressor__n_estimators': 200, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 1, 'regressor__max_depth': 3, 'regressor__learning_rate': 0.1}\n",
            "Best R² score found for Gradient Boosting:  0.8743079817058524\n",
            "Gradient Boosting RMSE: 26143.37\n",
            "Gradient Boosting R²: 0.9109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the SalePrice"
      ],
      "metadata": {
        "id": "NO9xWBJ9RQQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict using the best model\n",
        "y_test_pred = random_search.best_estimator_.named_steps['regressor'].predict(test_features_transformed)\n",
        "\n",
        "# Create a DataFrame for predictions\n",
        "if 'Id' in test_data.columns:\n",
        "    predictions = pd.DataFrame({\n",
        "        'Id': test_data['Id'],\n",
        "        'SalePrice': y_test_pred\n",
        "    })\n",
        "else:\n",
        "    predictions = pd.DataFrame({\n",
        "        'SalePrice': y_test_pred\n",
        "    })\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predictions.to_csv('predictions1.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Gt1azMsyDBdD"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}